# CSAPP (2022.1.4)

> 学习系统的唯一方法就是做(do)系统。

## 开始：

### 第一章、计算机系统漫游：

#### 1.9.1 Amdahl定律：

`Tnew = (1 - α)Told + (αTold) / k = Told[(1 - α) + α / k]`

加速比：`S = Told / Tnew = 1 / ((1 - α) + a / k)`

`Tnew`为改进后该部分程序运行的时间；`α`为该部分花的时间与总时间的比值。

> 该例子告诉我们：要想有整体的大幅改善，必须将整体都大幅改善，只做部分的大幅改善，整体的改善就相对小了。有点短板效应的意思。★★

## 第一部分：程序结构和执行：

### 第二章：信息的表示和处理：

#### 2.1.3 寻址和字节顺序：

计算机存储16进制数时有两种方法：如存储`0x01234567`

1. 大端法：
   
   | 地址范围 | 0x100 | 0x101 | 0x102 | 0x103 |     |
   |:----:|:-----:|:-----:|:-----:|:-----:|:---:|
   | ...  | 01    | 23    | 45    | 67    | ... |

2. 小端法：
   
   | 地址范围 | 0x100 | 0x101 | 0x102 | 0x103 |     |
   |:----:|:-----:|:-----:|:-----:|:-----:|:---:|
   | ...  | 67    | 45    | 23    | 01    | ... |

**可以通过强制类型转换(cast)或联合(union)来允许一种类型引用与它不同类型的对象。虽然大多应用编程不推荐，但是这对系统级编程非常重要：**

show_bytes.c:

```c
#include <stdio.h>

typedef  unsigned char *byte_pointer;

void show_bytes(byte_pointer start, size_t len) {
    size_t i;
    for (i = 0; i < len; ++i) {
        printf(" %.2x", start[i]);
    }
    printf("\n");
}

void show_int(int x) {
    show_bytes((byte_pointer) &x, sizeof(int));
}

void show_float(float x) {
    show_bytes((byte_pointer) &x, sizeof(float));
}

void show_pointer(void *x) {
    show_bytes((byte_pointer) &x, sizeof(void *));
}

void test_show_bytes(int val) {
    int ival = val;
    float fval = (float) ival;
    int *pval = &ival;
    show_int(ival);
    show_float(fval);
    show_pointer(pval);
}

int main() {
    test_show_bytes(12345);
}

/*
 * 输出结果：
 * 39 30 00 00
 * 00 e4 40 46
 * c8 18 e2 b5 f7 7f 00 00
 */
```

调用`show_bytes()`的那三个函数向其传送一个`&x`指针，它被强制类型转换了。

这种类型转换告诉编译器，程序应该把该指针看成指向一个**字节序列**，而非指向一个原始数据类型的对象。然后，这个指针会被看成是对象使用的最低字节地址。

**结果分析：**

`12345`十六进制表示为`003039`，可见 Mac 上是小端法表示。

#### 2.1.4 表示字符串：

文本数据比二进制数据有更强的平台独立性（跨平台）（同一编码下）。

#### 2.1.9 C语言中的位移运算：

1. 算术右移：负数时填`1`，正数时填`0`
2. 逻辑右移：填`0`

#### 2.2.3 补码编码：

用函数B2Tᴡ(Binary to Two's-complement)表示，长度为w。

**举例：**

```matlab
B2T₄([0001]) = -0*2³ + 0*2² + 0*2¹ + 1*2⁰ = 1
B2T₄([0101]) = -0*2³ + 1*2² + 0*2¹ + 1*2⁰ = 5
B2T₄([1011]) = -1*2³ + 0*2² + 1*2¹ + 1*2⁰ = -5
B2T₄([1111]) = -1*2³ + 1*2² + 1*2¹ + 1*2⁰ = -1
```

##### 反码：

最高位有效位的权是`-(2ᵂ⁻¹ - 1)`而不是`-2ᵂ⁻¹`，其他和补码一样。

##### 原码：

最高位是符号位。

#### 2.2.5 C 语言中的有符号数与无符号数:

在运算中，若一个参数为**有符号数**，而另一个为**无符号数**，那么有符号数会**隐式转换**为无符号数，并假设他们都是非负的。★

##### C语言中TMin的写法：

我们小心的将TMin₃₂写成`-2147483647-1`，而不是`-2147483647`或者`0x80000000`。

**C中的头文件<limits.h>：**

limits.h:

```c
#define INT_MAX 2147483647
#define INT_MIN (-INT_MAX - 1)
```

**原因：**

补码表示的不对称性和C语言的转换规则之间奇怪的交互。

#### 2.2.6 扩展一个数字的位表示：

**举例：**

```mathematica
[101] = -4 + 1 = -3
// 对他进行符号扩展：
[1101] = -8 + 4 + 1 = -3
```

**为什么？**

可以通过定义证明，将定义式展开，证明任意多个符号扩展等于不扩展。

> 关键点：`2ʷ - 2ʷ⁻¹ = 2ʷ⁻¹ `。★

**相当于：**

```mathematica
// 原来：
-2ʷ⁻¹ + ...

// 现在：
-2ʷ + 2ʷ⁻¹ + ...

// 就等于：
-2ʷ⁻¹

// 可以看到和原来相等
```

这就是二进制的神奇之处啊！！

##### 进制转换：short -> unsigned

先改变大小，再转换符号，即：`(unsigned) sx -> (unsigned)(int) sx`。

这个规则是C语言标准要求的。

#### 无符号数总结：

**避免使用无符号数：**

无符号运算容易出错，并且难以察觉。其实除C外很少有语言支持无符号整数，显然语言作者认为他的麻烦比好处要多得多。★

**无符号数的意义：**

当想把字仅仅看作是位的集合而没有数字意义时，它非常有用。

举例：

1. 布尔条件标记
2. 地址（对系统程序员很有帮助）
3. 实现模运算和多精度运算的数学包时，数字由字的数组表示

### 2.3 整数运算

#### 2.3.1 无符号加法：

**检测溢出：**

```mathematica
// 若：
s = x + y

// 当且仅当 s < x || s < y 时发生溢出
```

#### 2.3.3 补码的非：

##### 补码非的位级表示：

1. 全部取反，末尾加1(`-x = ~x + 1`)
2. 最后一个1前面全部取反

#### 2.3.6 乘以常数：

##### 编译器对乘法的优化：

以位移、加法和减法的组合来代替。

**原因：**乘法的代价比位移和加法要大得多

**举例：**

```c
y = x * 14;

// 14 = 2³ + 2² + 2¹
// =>

y = (x << 3) + (x << 2) + (x << 1);

// 或者 14 = 2⁴ - 2¹
// =>

y = (x << 4) - (x << 1);
```

### 2.4 浮点数：

浮点数不会关注太多精确性，把实现的速度和简便性看得更重要。

#### 2.4.2 IEEE浮点表示：

**1. 规格化的值：**

阶码：`E = e - Bias`

e：无符号数

Bias（偏置值）：`2ᴷ⁻¹ - 1`

尾数：`M = f + 1`（隐含1开头）

**2. 非规格化的值：（阶码域全为0）**

阶码：`E = 1 - Bias`

尾数：`M = f`（不隐含1开头）

**非规格化值的两个功能：**

1. 表示0，有+0.0（全0）和-0.0（符号位为1，其他为0），他们在某些方面被认为不同，而其他方面相同。
2. 表示非常接近于0.0的数。可能的数值分布均匀的接近于0.0

**3. 特殊值：（阶码全1）**

情况1. 小数域全0:

1. s=0, -> +∞
2. s=1, -> -∞

情况2. 小数域非0:

NaN。（结果不能是实数或无穷），如：√-1或∞-∞

#### 2.4.5 浮点运算：

可交换，但不可结合，也不可分配，如：

```mathematica
// 舍入
(3.14 + 1e10) - 1e10 = 0.0

3.14 + (1e10 - 1e10) = 3.14
```

### 第三章、程序的机器级表示：

#### 3.2.1 机器级代码：

**虚拟地址**提供的内存模型看上去是一个非常大的数组。

#### 3.2.3 关于格式的注解：

汇编代码有两种格式：

1. ATT
2. Intel

#### 3.4.1 操作数指示符：

操作数：

1. 立即数(immediate) -> `$+C语言整数`：表示常数
2. 寄存器 -> `rₐ表示任意寄存器a，R[rₐ]表示他的值`（将寄存器看作数组）：表示寄存器的内容
3. 内存引用 -> `Mb[Addr]表示从地址 Addr 开始的b个字节值的引用`：使用计算出来的地址访问某个内存位置。

#### 3.4.3 数据传送示例：

**C与汇编：**

1. 指针就是地址
2. 局部变量不在内存中，而在寄存器中。而访问寄存器要快得多。（利用好局部变量，可以提升程序性能，启下）

#### 3.6.5 用条件控制来实现条件分支：

##### 使用`goto`语句时不好的编程风格？

它会使代码难以阅读和调试。

##### C与汇编的`if-else`：

```c
if (test-expr)
  then-statement
else 
  else-statement
```

```assembly
t = test-expr
if (!t)
 goto false;
then-statement
goto done;
false:
 else-statement
done:
```

#### 3.6.6 用条件传送来实现条件分支

原始的条件操作：

控制的条件转移：条件满足，走一条路；不满足，走另一条。

但是在现代处理器上很**低效。**

**替代？**

数据的条件转移：计算条件操作的两种结果。

**举例：**

```c
long cmovdiff(long x, long y)
{
  // 数据替换
  long rval = y - x;
  long eval = x - y;

  long ntest = x >= y;

  // 数据替换
  if (ntest) rval = eval;
  return rval;
}

// 等价于 if (test) ...
//              else ...
```

#### 3.7.1 运行时栈：

x86-64 的栈向低地址增长，即：上面是栈底，地址从下往上增大。★

#### 3.7.6 递归过程：

过程调用在栈中有自己的私有空间，不会相互影响。

**递归：**

先把已有的值保存在栈上，随后在返回前恢复。

递归调用自己与调用其他函数是一样的。★

#### 3.9 异质的数据结构：

1. 结构(structure)，即：结构体：将多个对象集合到一个单位中。
2. 联合(union)：允许用几种不同的类型来引用一个对象。

#### 3.9.2 联合：

**作用：**

能规避C的类型系统。

**举例：**

```c
union U3 {
  char c;
  int i[2];
  double v;
}
```

**各部分大小与对应的结构体：**

| 类型  | c   | i   | v   | 大小  |
|:---:|:---:|:---:|:---:|:---:|
| S3  | 0   | 4   | 16  | 24  |
| U3  | 0   | 0   | 0   | 8   |

**原因：**

union U3* 的指针 p，p -> c、p -> i[0] 和 p->v 引用的都是数据结构的起始位置。★

联合的总大小等于最大的字段大小。★

#### 3.9.3 数据对齐：

Intel 建议数据对齐以提高系统性能。

**对齐原则：**任何K字节的基本对象的地址是K的倍数。

**强制对齐：**某些型号的Intel和AMD处理器对有些实现多媒体操作的SSE指令，若不对齐则不能正确执行。（不满足对齐要求的地址访问内存会导致异常，默认行为是终止程序）

#### 3.10.1 理解指针：

指针不是机器代码的一部分：是C提供的抽象，帮助程序员避免寻址错误。

#### 3.10.2 应用：使用GDB调试器：

**使用步骤：**

1. `objdump -d prog`
2. `gdb prog`

> DDD 是 GDB 的图形界面版本。

#### 3.10.3 内存越界引用和缓冲区溢出：（也是一种攻击方式）

使用C语言的库函数时要注意。

#### 3.10.4 对抗缓冲区溢出攻击：

##### 1. 栈随机化：

**原理：**

程序开始时，在栈上分配一段 0~n 字节之间的随机大小的空间。

**作用：**

使得攻击者不容易立马猜中某程序所使用的栈空间，增加了攻击难度。

**常见攻击方式：**

在攻击代码前面添加nop(读作"no op", no operation 的缩写 -> 作用：使程序计数器加一)，挨个个程序起始地址枚举；若猜中，程序滑过这个序列，到达攻击代码。（空操作雪橇(nop sled)，即程序滑过该序列(nop)。）

##### 2. 栈破坏检测：

**原理：**

在栈帧中任何局部缓冲区与栈状态之间存储一个特殊的**金丝雀(canary)值**，即**哨兵值(guard value)**；它随机产生，在恢复寄存器状态和从函数返回之前，检查它是否改变，若改变，则程序异常终止。

**优点：**

性能损失小。

##### 3. 限制可执行代码区域：

**优点：**

由硬件完成，效率上没有损失。

##### 总结：

**3种方法的共同点：**

1. 不需要程序员做任何特殊的努力
2. 带来的性能代价小。

> 记住，只能降低被攻击率，而不能防止，毕竟道高一尺，魔高一丈。

#### 3.10.5 支持变长栈帧：

`%rbp`中bp的由来：为了管理变长栈帧，x86-64代码使用寄存器`%rbp`作为帧指针（有时称基指针(**base pointer**))。

#### 3.11 浮点代码：

一些支持图形和图像处理的**媒体指令**，其**本意**是允许多个操作以并行模式执行。

### 第三章、处理器体系结构：

> 现代微处理器可以称得上时人类创造的最复杂的系统之一。

HCL(Hardware Control Language)硬件控制语言：用以描述处理器设计。

#### 4.1.3 指令编码：

每条指令的第一个字节表明指令的类型：高四位是代码部分，低四位时功能(function)部分。

**寄存器的编码：**不需要访问寄存器时，将寄存器ID置为0xF。

**整数的编码：**小端法。

**指令集的性质：**字节编码要有唯一的解释。**作用：**确保执行代码无二义性。

**RISC与CISC指令集：**

x86-64 -> 复杂指令集计算机 -> CISC（读作"sisk"）；精简指令集计算机 -> RISK (读作"risk")。

#### 4.1.5 Y86-64 程序：

**Y86-64 汇编代码中：**

以`.`开头的词是汇编器伪指令(assembler directives)，他们告诉汇编器调整地址，以便在那产生代码或插入数据。

#### 4.1.6 一些Y86-64指令的详情：

**注意：**

`pushq`指令会把栈指针减8，并将一个寄存器值写入内存中，因此，执行`pushq %rsp`时，处理器的行为是不确定的，因为要入栈的寄存器会被同一条指令修改。

此时有两种**约定：**

1. 压入`%rsp`的原始值
2. 压入它减8后的值

这与x86处理器型号有关。

**缺点：**

1. 降低了代码的可移植性
2. 增加了文档的复杂性

**总结：**

长远看来，提前了解细节，力争保持一致，能省去很多麻烦。

#### 4.2 逻辑设计和硬件控制语言HCL

电路设计的演变：**

画逻辑电路图(纸、笔) -> ...(计算机图形终端) -> 硬件描述语言(Hardware Description Language, HDL)。

**对比：编程的演变：**

汇编 -> 高级语言，用编译器产生机器代码。

**HDL：（最常用的是 Verilog，语法类似C；VHDL，类似Ada）**

描述硬件结构，而不是程序行为。（虽然看上去和编程语言类似）

现在已经有了将HCL直接翻译成Verilog的工具。

> 控制逻辑是设计微处理器最难的部分。

#### 4.2.2 组合电路和HCL布尔表达式：

**HCL与C的区别：**

**1. `=`：**

C：执行将结果存入内存中

HCL：给表达式一个名字

**2. 逻辑表达式：**

C：部分求值

HCL：简单的响应输入的变化（不部分求值）

#### 4.2.5 存储器和时钟：

**寄存器的区别：**

硬件：寄存器直接将它的输入和输出线连接到电路的其他部分 -> 物体

机器级编程：CPU中为数不多的可寻址的字，地址是寄存器ID。这些字通常存在寄存器文件中 -> CPU中寻址空间的地址

**时钟寄存器的作用：**

保存程序计数器（PC）、条件代码（CC）和程序状态（Stat）。

#### 4.3.3 SEQ的时序：

**原则：从不回读：**

处理器只读有关该指令的内容，该指令做了什么在执行该指令时不用管，以后需要用到时再读取。

**SEQ的缺点：**

太慢。(时钟必须非常慢，才能使一个信号在一个周期内传播所有的阶段)

#### 4.4 流水线通用原理：

**流水线的重要特性：**

提高了系统的吞吐量（单位时间内服务的顾客总数）

**缺点：**

轻微地增加了延迟（服务一个用户所需的时间）-> 多开了几个窗口，每个窗口都需要排队了，并且只能按特定顺序，一个个窗口挨着来，切换窗口也许要时间。

#### 4.4.1 计算流水线：

**增加吞吐量的代价：**

硬件增加，延迟增加（因为增加了寄存器，经过它也许要时间）

#### 4.4.3 流水线的局限性：

##### 1. 不一致的划分：

**硬件设计的挑战：**

因为流水线每个部分延迟不同的话，会导致延迟短的部分一直空闲，而延迟长的部分一直工作，效率就不高，所以应该将系统划分为具有相同延迟的阶段。但是并不容易，因为某些硬件，如ALU和内存，不能被划分为多个延迟较小的单元。

##### 2. 流水线过深：

会导致收益下降，因为延迟太高，而吞吐量相对没有翻倍。

**现代处理器：**

1. 每阶段延迟小 -> 处理器架构师将指令划分为非常简单的步骤。
2. 硬件延迟小 -> 电路设计者小心设计流水线处理器
3. 时钟延迟小 -> 芯片设计者小心设计时钟传播网络，保证时钟在整个芯片上同时改变

#### 4.5.1 SEQ+：重新安排计算阶段：

**SEQ+的特色：**

没有硬件寄存器来存放程序计数器，根据前一条指令保存下来的信息动态计算PC。

#### 4.5.2 插入流水线寄存器：

**流水线寄存器标号：（保存一条指令的各个阶段的状态）**

- F：作用：保存程序计数器的预测值
- D：作用：保存关于最新取出指令的信息，阶段：位于取值和译码阶段间，处理：由译码阶段处理
- E：作用：保存关于最新译码的指令和从寄存器文件读出的值的信息，阶段：位于译码和执行阶段之间，处理：由执行阶段处理
- M：作用：保存最新执行的指令的结果、关于用于处理条件转移的分支条件和分支目标的信息，阶段：位于执行和访存阶段之间，处理：由访存阶段处理
- W：作用：反馈路径将计算出来的值提供给寄存器文件写、当完成`ret`指令时，向PC选择逻辑提供返回地址，阶段：位于访存阶段和反馈路径之间

#### 4.5.4 预测下一个PC

**技术：**

分支预测。

研究表明，**总是选择分支**的预测策略，成功率约为60%。

**使用栈的返回地址预测：**

大多程序，预测返回值很容易，因为过程调用和返回成对出现，大多函数调用，会返回到调用后的那条指令。所以，可以利用这个属性，在取指单元中放入一个硬件栈，保存过程调用指令产生的返回地址，每次执行，将返回地址压栈，当取出返回地址时，弹栈作为预测值。高性能处理器会运用这个属性。★

#### 4.5.5 流水线冒险：

1. 数据相关：下一条指令会用到这一条指令计算出的结果
2. 控制相关：一条指令要确定下一条指令的位置，如：在执行跳转、调用或返回指令时。

##### 解决：

**1. 暂停：**

优点：简单

缺点：性能不好

**2. 转发：**

在寄存器间另开一条路，直接将需要的数据转发给那个阶段。

优点：不用等待，性能好

缺点：需要在基本的硬件结构中增加一些额外的数据连接和逻辑控制，操作复杂。

**3. 加载/使用数据冒险：（不能用转发解决，但是将转发和暂停结合就好了）**

在下一个周期才产出本周期需要使用的值，转发不能将值传送回过去的时间。

**加载互锁：**用暂停来处理加载/使用冒险。

将加载互锁和转发结合足以处理所有的数据冒险。★

**4. 避免控制冒险：**

**控制冒险：**处理器无法确定下一条指令的地址。（只会发生在`ret`指令和跳转指令，并且后一种只有在预测错误时才会造成麻烦）

**解决：**

1. ret：暂停
2. 跳转：在指令阶段中插入气泡，并取出跳转指令后面的指令，就能将预测错误的指令取消，并且保存了状态，使程序得以继续运行。

#### 4.5.6 异常处理：

**基本原则：**流水线中最深的指令引起的异常，优先级最高。（先把后面的解决了，如果成功，就完事儿了；否则，再解决前面的。若先把前面的解决了后面的大概率还是会报错）

**异常返回方式：**

状态码：在每个流水线寄存器中包括一个状态码stat，随着流水线传播，指到写回阶段被控制逻辑发现，停止执行。

#### 4.5.7 PIPE各阶段的实现：

流水线化的实现应该总是给处于最早流水线阶段中的转发源以较高的优先级，因为它离要用它的阶段最近。画一下流水线的图就明白了，同一周期中前面的阶段离下面的阶段最近。★

#### 4.5.8 流水线控制逻辑：

没有办法在流水线的取指阶段插入气泡。

### 第五章、优化程序性能

**要点：**

1. 选择适当的数据结构和算法
2. 编写编译器能够优化的源代码
3. 削除不必要的操作

#### 5.1 优化编译器的能力和局限性：

优化级别`-O2`已经成为了被接受的标准，但是还是主要考虑`-O1`编译出的代码。

**妨碍编译器优化的因素：**

1. 看似表达式效果相同，但实际上在某些特殊情况下他们的结果并不相同，编译器不会去冒这个险帮你优化
2. 两个不同的指针可能指向同一个内存地址，所以当他们地址相同和不同时，计算结果不同
3. 改变调用次数程序的行为不同的函数

总结：

编译器不会冒险去优化可能产生不同结果的代码，这就会限制优化策略。

**优化策略之内联函数替换函数调用：**

缺点：

GCC：只能在单个文件中使用这种优化，无法用于大多数情况（调用其他文件的函数）

建议：

某些情况下应该组织编译器内联替换：

1. 使用符号调试器（如：GDB）评估代码 ── 无法打断点
2. 代码剖析评估程序性能 ── 用内联替换的函数无法被正确剖析

**编译器的优化能力：**

GCC的优化能力不错，但是不是激进分子（冒险），所以需要编写出一手方便优化的代码。

#### 5.3 程序示例：

**边界检查：**

优点：减少出错

缺点：性能损失

**优化级别建议：**

使用`-O1`或者`-Og`，这样什么都不用做就能将性能提升**两倍**以上。

#### 5.4 削除循环的低效率 ★

将在循环中要执行多次但是结果不会变的移出循环，使用一个局部变量来保存它，就避免了重复计算。

> 虽然编译器也可能试着完成这种优化，但是这样的分析已经远远超出了编译器的能力，需要自己优化。

这样的小优化带来的好处是显而易见的，大型项目中这样一个小地方就可能是性能瓶颈，并且很难发现。一个有经验的程序员就要避免引入这样的低效率。

#### 5.5 减少过程调用：

不在循环中使用函数来访问向量，而是向数组一样直接通过下标访问。

#### 5.6 削除不必要的内存引用：

**内存引用：**

C语言在循环中将结果赋值给向量，会导致每次都从内存读入再写到内存，大大降低了性能，因为每次迭代开始的值就是上次最后写入的值。

**解决：**

将累积值用变量保存起来，最后再赋给向量。性能显著提升。

这里编译器依然无法优化，因为它无法判断程序员的本意。

#### 优化总结：

可以发现优化点主要在循环上。

#### 5.7 理解现代处理器：

要想作出进一步的提升，还需要结合实际的机器使用的处理器硬件设施。但是通用原则总是不变的。

由于现代处理器是大量晶体管集中到一块芯片上，所以在代码级上看似是一条条执行，实际上是多条并行执行的。

**限制程序性能的因素：**

1. 指令必须按顺序执行时，即下一条指令开始前，该指令必须结束。（限制了处理器利用指令集并行的能力）── 延迟界限
2. 处理器单元的原始计算能力。（单核性能）── 吞吐量界限

#### 5.8 循环展开：

将循环增量`i`从加一增加到加二，然后一次循环中进行两次操作。（甚至更高，以此类推）

> 编译器很容易执行循环展开，只要将优化级别设置得足够高。（GCC: 3及以上）所以并不需要手动展开。★

#### 5.9.1 多个累积变量：

在循环展开中使用两个（或多个）累积变量，来利用CPU的并行性。（有些编译器也能做到）

**注：**

浮点数的乘法不可结合，如果乱优化可能导致结果上溢或下溢，导致结果与优化前不同。但这种情况比较少，还是性能比较重要。

但也不能乱优化，最好与用户协商，看看优化后的算法产生不同结果能否接受。（客户需求才是最重要的）

大多数编译器不会冒险优化浮点代码。

> AVX指令集不包括64位整数的并行乘法指令，因此GCC无法为其生成向量代码。

#### 5.10 优化合并代码的结果小结：

现代处理器计算能力了得，但我们需要按照非常程式化的编程方式来将其能力诱发。

#### 5.11.1 寄存器溢出：

并行度超过了可用寄存器的数量。（相当于缓存满了，需要到内存中去替换，消耗性能）

若溢出，那么维护多个累积变量的优势将会消失。幸运的是，x86-64有足够多的寄存器，大多循环在出现溢出之前就达到吞吐量限制。

#### 5.11.2 分支预测和预测错误处罚：

通过尝试，试出容易被翻译成条件数据传送的代码。（检查产生的汇编代码，测试性能）

#### 5.14 确认和削除性能瓶颈：

> 处理大程序时，连知道应该优化什么地方都是很难的。

#### 5.14.1 程序剖析：

Unix 剖析工具 ── GPROF：

**更成熟的工具：**

Intel：VTUNE

Linux：VALGRIND

**作用：**

1. 对每个函数计时
2. 函数调用次数

**使用：**

1. `gcc -Og -pg prog.c -o prog`（`-Og`非常重要，阻止编译器进行函数内联替换，来保证正常跟踪函数）(注：OS X 10.9 之后就不支持`-pg`选项了)
2. `./prog file.txt` ── 运行比平时慢2倍，产生一个`gmon.out`文件
3. `gprof prog`

GPROF注意事项：**

1. 计时不准确：间隔计数，每隔一个固定的时间间隔 (1~10ms) 将程序中断一次，中断时，判断在执行的函数，然后将该间隔加上该函数的计时器上。因为是固定间隔，所以该函数可能刚执行，就给它加上从上次中断以来的时间间隔；或者两次中断间执行的函数没有记录时间花费。（该程序适用于剖析执行时间长的函数，执行时间短的看成估计值即可）
2. 调用信息可靠：为调用者和被调用者维护一个计数器，调用时加一。（没有执行内联替换）
3. 默认不显示对库函数的计时：被计算到调用他们的函数的时间中

#### 5.15 小结：

没有任何编译器能用一个好的**算法和数据结构**代替低效率的算法或数据结构，设计该部分才是程序员该关注的重点。★★

### 第六章、存储器层次结构：

#### 6.1.1 随机访问存储器：

**1. 静态RAM：SRAM**

特性：双稳态，就像一个倒立的钟摆，要么倒在左边，要么倒在右边，在中间是不稳定的，随时可能倒向一边。

只要有电，就会永远保持它的值，即使有干扰，干扰削除时，电路就会恢复到稳态。

**2. 动态RAM：DRAM**

特性：对干扰敏感，一旦被干扰，就不能恢复了。数码相机的传感器本质上就是DRAM单元的阵列。

若发生干扰，DRAM单元会在10~100ms内失去电荷，幸运的是，计算机运行的时钟周期以`ns`衡量，所以相对而言能保持比较长的时间。内存系统必须周期性的读出、重写来**刷新**DRAM。

**SRAM与DRAM对比：**

1. SRAM更快、稳定
2. 但是需要更多晶体管，造价更贵，功耗更大

**3. 传统的DRAM**

DRAM芯片中的单元被分为d个**超单元**，每个超单元由w个DRAM单元组成。

DRAM被组织成二维阵列的原因：

降低芯片上的引脚数量。

缺点：

分两步发送地址，增加了访问时间。

**6. 非易失性存储器：（ROM）**

断电也不会丢失信息。（DRAM和SRAM断电会丢失信息）

固件：存储在ROM设备中的程序。

#### 6.1.2 磁盘存储：

**1. 构造：**

一根竖棒，上面串着几块盘片。。。

**4. 逻辑磁盘块：**

格式化磁盘：格式化需要留下一些柱面来备用，所以厂商说的格式化容量通常比最大容量小。

**5. 连接I/O设备：**

IO总线的特征：

优点：兼容性强（兼容多种第三方I/O设备）

缺点：比系统总线和内存总线慢

**6. 访问磁盘：**

直接内存访问（DMA）：设备可以自己执行读或者写总线事务而不需要CPU的干涉。

磁盘控制器通过发送中断信号到CPU引脚来通知CPU，CPU此时暂停工作并执行中断处理程序。

#### 6.1.3 固态硬盘：（SSD）

读比写快。

只有页所属的整个块被擦除后才能进行写操作。大约100 000次重复写之后，块被磨损坏，无法再使用。

写慢的原因：

1. 擦除块比较慢：1ms级，比读高一个数量级
2. 若试图修改一个还有数据的页，就需要移动这个块的数据到一个被擦除的块，然后才能修改

延长寿命：

闪存翻译层中的平均磨损逻辑将擦除平均分布在所有块上。

#### 6.1.4 存储技术趋势：

增加密度比降低访问时间容易得多。

#### 6.2 局部性：★

一个编写良好的程序常常具有良好的局部性。

**局部性原理：**

一个程序倾向于引用邻近于其他最近引用过的数据项的数据项，或者最近引用过的数据项本身。（如：若引用了数组的第一项，就倾向于再次引用它后面的数据）

**局部性分类：**

1. 时间局部性：在将来多次引用同一个内存位置
2. 空间局部性：在将来引用该内存位置附近的内存位置

#### 6.2.1 对程序数据引用的局部性：

随着步长(`i=i+1: 步长为1`)的增加，空间局部性下降。（对数组的遍历（特别是二维数组）最好遵循空间局部性（循环的顺序），否则性能会很差）

#### 6.2.2 取指令的局部性：

**代码于程序数据的区别：**

在运行时代码不能被修改。

#### 6.3 存储器层次结构：

层次结构可能会不同（许多站点（包括Google数据中心）将本地磁盘备份到存档的磁带上）

无论哪种情况，磁带都是存储器层次结构中的一层，在本地磁盘层下面。

#### 6.3.1 存储器层次结构中的缓存：

离CPU越远，访问时间越长，所以，为了弥补，倾向于使用较大的块。（提高缓存命中率，访问时间越长，不命中的代价就越大：一是替换花的时间长；二是下级未命中，说明上面的都未命中）

**缓存管理：**

大多情况，缓存自动运行，不需要程序采取特殊行动。

#### 6.4.2 直接映射高速缓存：

把块看成字节数组，字节偏移量是到这个数组的索引。（有一个基值，即该数组的起始地址，然后加上偏移量，即可获取该地址）

> 根据我们的经验，在学生做个几个这样的练习之前，布尔诺那个真正理解高速缓存是如何工作的。

**抖动（thrash）：**

反复加载和驱逐相同的高速缓存块的组。

**为什么用中间的位来做索引？**

若用高位做索引，一些连续的内存块会被映射到相同的缓存块，此时若访问一个数组，就会发生不断驱逐同一个块的元素，效率地下；而使用中间位做索引，就能将这些块分开。（画个图就懂了）

#### 6.4.5 有关写的问题：

##### 写已经缓存了的字（命中）：

**1. 直写(write-through)：**

立即将修改后的值写入低一级的缓存中。

优点：简单

缺点：每次写都会引起总线流量

**2. 写回(write-back)：**

推迟更新，只有它快淘汰时才写入低一层。

优点：能显著减少总线流量（局部性）

缺点：增加了复杂性（必须为每个高速缓存行维护一个额外的修改位（dirty bit）

##### 写未缓存的字（不命中）：

**1. 写分配(write-allocate)：**

先加载相应的块到低一级的缓存中，然后更新自己。

优点：利用空间局部性

缺点：每次不命中都会导致一个块从低一级传送到高层

**2. 非写分配(not-write-allocate)：**

绕过高速缓存，直接写入低一级中。

直写通常是非写分配的；而写回是写分配的。

**总结：**

为写操作优化高速缓存是一个细致而困难的问题，因为它随系统不同而不同，是私有的，文档不全。

**建议：**

使用**写回和写分配**模型。

**原因：**

1. 由于较长的传送时间，低层更可能使用写回。（如：虚拟内存系统（用主存作为存储在磁盘上的块的缓存）只使用写回）
2. 由于逻辑电路密度的提高，写回的高复杂性越来越不成为阻碍
3. 现代系统所有层次都能看见写回缓存，符合当前趋势
4. 与处理读的方式对称，良好利用空间和时间局部性

#### 6.4.7 高速缓存参数的性能影响（基于多次实验）：

越下层，传送时间增加，减少传送的数量就很重要，越可能使用写回。

#### 6.5 编写高速缓存友好的代码：

程序把大部分时间花在少量核心函数上，而这些函数把大部分时间花在**循环**上，所以，关注这些地方，而忽略其他地方。

#### 6.6.1 存储器山：

`run`函数的参数`size`和`stride`允许我们控制产生出读序列的时间和空间局部性程度。

**寄存器山：**反复以不同的`size`和`stride`值调用`run`函数，能得到一个读带宽的时间和空间局部性的二维函数。

## 第二部分：在系统上运行程序：

### 第七章、链接：

链接可以在编译（源代码被翻译成机器语言时）、加载（程序被加载器加载到内存并执行时）或者运行时（由应用程序来执行）。

虽然表面上的东西大有不同，但是基本的链接概念是通用的；虽然细节不同，但概念是相同的。这告诉我们要掌握那些不变的部分，才能懂得其基本思想，以不变应万变。

#### 7.1 编译器驱动程序：

**链接的过程：**

源文件：通过翻译器 -> 可重定位目标文件(`*.o`)：通过链接器 -> 完全链接的可执行目标文件。

#### 7.2 静态链接：

**关于链接器：**

1. 目标文件纯粹是字节块的集合
2. 链接器对目标机器了解甚少，产生目标文件的编译器和汇编器已经完成了大部分工作

#### 7.3 目标文件：

**目标文件的格式：**

1. 第一个Unix：`a.out`
2. Windows: Portable Executable (PE)
3. MacOS-X: Mach-O
4. 现代x86-64 Linux和Unix：可执行可链接格式(Executable and Linkable Format, ELF)

不管哪种格式，基本概念都相同。

#### 7.4 可重定位目标文件：

**.bss(Block Storage Start):**

标文件格式区分已初始化和未初始化的原因：

空间效率：未初始化变量不需要占实际的磁盘空间，运行时才在内存中分配这些变量，初始值为0。

**.symtab：**

一个符号表：与编译器中的不同，它不包含局部变量条目。

#### 7.5 符号和符号表：

> C程序员使用`static`属性隐藏内部变量和函数声明，就像 Java 和 C++中的`public`和`private`一样。

`.symta`节中包含ELF符号表，每个符号都被分配到目标文件的某个节。有三个特殊的伪节：ABS、UNDEF和COMMON。

**注意：**只有可重定位目标文件中才有这些伪节，可执行目标文件中没有。★

#### 7.6 符号解析：

**对全局符号的解析很棘手：**

会假设该符号在其他模块已经定义了，但是可能会遇到多个模块中定义的全局变量名字相同的问题。

**C++和Java中链接器符号的重整：**

这两种语言允许方法重载，那么链接器怎么区分这些同名函数？

编译器将每个唯一的方法和参数列表**组合编码**成一个对链接器来说唯一的名字 -> 解决了上述**名字冲突**问题。

#### 7.6.1 链接器如何解析多重定义的全局符号？

**规则：**

1. 不允许有多个同名强符号
2. 如果有一个强符号和多个弱符号，选强
3. 如果多个弱符号同名，任选一个

**注意：**链接器通常不会表明它检测到多个同名变量的定义。-> 所以应该由程序员来避免。

> 这种细微的错误非常难以察觉。

**当怀疑可能出现同名变量时：**

1. 使用像`GCC-fno-common`标志这样的选项调用链接器，使链接器遇到多重定义的全局符号时报错，而非警告
2. 使用`-Werror`选项，把所有警告变为错误。

#### 7.6.2 与静态库链接：

**静态库：**

编译系统提供的一种机制，即将所有吸纳公关的目标模块都打包成一个单独的文件，这就是静态库。-> 存储标准库函数的地方

#### 7.6.3 链接器如何使用静态库来解析引用？

注意命令行中库和目标文件的**顺序**：即要手动保证把声明的函数放在定义的函数的前面，否则会导致**令人困扰的错误**。

#### 7.9 加载可执行目标文件：

在终端输入命令：`./prog`：

`prog`不是内置shell命令，所以shell会认为他是一个可执行文件，通过调用存储器中的**加载器**的操作系统代码来运行它。任何Linux程序都可以通过调用`execve`函数来调用加载器。

**加载器的工作原理：**

加载器将可执行目标文件的代码和数据从磁盘复制到内存中，然后通过跳转到程序的第一条指令或入口来执行程序。这个将程序复制到内存并运行的过程叫做**加载**。

**其他细节：**

1. 由于`.data`段有对齐要求，所以代码段和数据段之间有**间隙**。
2. 在分配栈、共享库和堆段运行地址的时候，链接器还会使用地址空间布局随机化(ASLR)。虽然每次运行程序时地址会变，但是他们的**相对位置**不变。

#### 7.10 动态链接共享库：

**内存的一个有趣属性：**

无论系统的内存有多大，它总是一种稀缺资源，磁盘空间也一样，就像厨房垃圾桶。

**共享库(shared library)：**

致力于解决静态库的缺陷。是一个目标模块，在运行或加载时，能够加载到任意内存地址，并和一个在内存中的程序链接。这个过程叫做**动态链接**。

共享库又称共享目标(shared object)，在Linux中常用后缀`.so`表示；Windows中共享库称为DLL(动态链接库)。

**命令解析：**

`gcc -o prog21 main2.c ./libvector.so`：此时没有任何`libvector.so`的代码和数据节真的被复制到可执行文件`prog21`中；反之，链接器复制了一些重定位和符号表信息，使得运行时可以解析对`libvector.so`中代码和数据的引用。★

#### 7.11 从应用程序中加载和链接共享库：

**Java本地接口(Java Native Interface, JNI)：**

允许Java程序调用“本地的”C和C++函数。

基本思想：将本地的C函数(foo)编译到一个共享库中(foo.so)。但当一个Java程序试图调用函数`foo`时，Java解释器利用`dlopen`接口（或与其类似的接口）动态链接和加载`foo.so`，然后再调用`foo`。

#### 7.12 位置无关代码(Position-Independent Code, PIC)：

可以加载而无需重定位的代码。用户对GCC使用`-fpic`选项指示GNU编译系统生成PIC代码。共享库的编译必须**总是**使用该选项。

共享库的一个**主要目的**：

允许多个正在运行的进程共享内存中相同的库代码。

#### 7.13 库打桩机制──Linux链接器支持的一个强大的技术：

允许你截获库函数的调用，而执行自己的代码。

使用库打桩机制，你可以追踪某个函数的**调用次数**，验证和追踪它的输入和输出值，或者甚至把它替换为一个完全不同的实现。

#### 7.14 处理目标文件的工具包：

GNU binutils包：

1. AR
2. STRINGS
3. STRIP
4. NM
5. SIZE
6. READELF
7. OBJDUMP
8. LDD

#### 7.15 小结：

许多链接器**从左到右**扫描解析符号引用。★

### 第八章、异常控制流：

现代系统通过使控制流发生突变来对某些情况作出反应，这些突变就叫做**异常控制流(Exceptional Control Flow, ECF)**。

#### 8.1 异常：

程序出现异常 -> 通过中断告诉CPU -> 异常处理程序 -> 程序终止或者返回中断处继续执行：若中断时该指令未执行完，那么继续执行该指令；否则，执行下一条指令。

#### 8.1.3 Linux/x86-64 系统中的异常：

**关于术语的解释：**

有些制造厂商的手册会使用“异常”仅仅表示同步事件引起的控制流的改变。

#### 8.2 进程：

进程是计算机科学中最深刻、最成功的概念之一。

**定义：**

一个执行中程序的实例。

系统中每个程序都运行在某个进程的上下文(context)中，上下文是由程序正确运行所需的**状态**组成的。

**进程提供给应用程序的关键抽象：**

1. 一个独立的逻辑控制流，它提供一个假象，好像我们的程序独占地使用处理器
2. 一个私有的地址空间，它提供一个假象，好像我们的程序独占地使用内存系统

#### 8.2.1 逻辑控制流：

**关键点：**

进程轮流使用处理器。

#### 8.2.4 用户模式和内核模式：

处理器用某个控制处理器中的一个**模式位(mode bit)**来提供该功能。当设置了模式位时，进程就运行在内核模式中（有时也叫**超级用户模式**）；没有设置模式位时，运行在用户模式，不能直接引用地址空间中内核区的代码和数据（会导致致命的保护故障），必须通过系统调用接口间接访问。

**进程如何从用户模式变为内核模式？**

通过中断、故障或者陷入系统调用这样的异常。

**`/proc`文件系统：**

允许用户模式进程访问内核数据结构内容。

`/proc`文件系统将许多内核数据结构的内容输出为一个用户程序可以读的文本文件的层次结构，如：可以找出一般的系统属性：/proc/cpuinfo`是有关CPU的；某个进程使用的内存段(`/proc/<process-id>/maps`)；2.6 版本的Linux内核引入`/sys`文件系统，输出关于系统总线和设备的额外的低层信息。

#### 8.2.5 上下文切换：

先保存信息，再切换。

#### 8.3 系统调用错误处理：

程序员应该总是检查错误，但很多人都会忽略，因为他们使代码变得臃肿、难读。

#### 8.4.2 创建和终止进程：

进程标识：PID，这是父子进程最大的区别。

**fork()函数：**

它只被调用一次，但返回两次，一次在父进程中，一次在新创建的子进程中。在父进程中，返回子进程的PID；在子进程中，返回0，所以可以用返回值来区分程序在子进程还是父进程中执行。

**关于父子进程：**

1. 父子进程并发执行，独立运行
2. 在相同的地址空间中，却又有自己私有的地址空间
3. 共享文件

通过画**进程图**可以非常直观了当的展现出`fork()`函数的过程。

#### 8.4.3 回收子进程：

**为什么已终止的子进程被成为僵死进程？**

僵尸是活着的尸体，是一种半生半死的实体。僵死进程终止了，但是内核仍保留着他的某些状态直到负进程回收它为止，从这个意义上来说他们是类似的。

**父进程回收僵死进程之前就终止了怎么办？**

内核会安排`init`进程成为它的孤儿进程的养父。`init`的PID为1，是系统启动时内核创建的，它不会终止，是所有进程的祖先。

长时间运行的程序，如：shell 或者服务器，总是应该回收他们的僵死进程，因为即使他们没有运行，却仍然消耗系统的内存资源。

**Unix中查函数头文件：**

用`man`命令查询该函数，即可查出其头文件。

**子进程回收的顺序？**

更并发一样，没有特定的顺序，跟机器相关。

#### 8.4.5 加载并运行程序：

`execve`函数在当前进程的上下文中加载并运行一个新程序。

**`execve`与`fork`的区别：**

1. `fork`调用一次返回两次；`execve`调用一次不返回（只有出现错误时，如找不到`filename`时，`execve`才返回到调用程序）。
2. `fork`在新的子进程中运行相同的程序，新的子进程是父进程的一个复制品；`execve`在当前进程的上下文中加载并运行一个新的程序，他会覆盖当前进程的地址空间，但并没有创建一个新的进程。新的程序仍然有相同的PID，并且继承了调用`execve`时已打开的所有文件描述符。（`fork`在一个进程中创建一个新的进程，执行同样的一段代码；`execve`在同一个进程中创建一个新的程序，执行新的一段代码，并覆盖现在的地址空间）

**程序与进程的区别（帮助理解`fork`与`execve`的差异）：**

程序是一堆代码和数据，程序可以作为目标文件存在于磁盘上，或者作为段存在于地址空间中；进程是执行中程序的一个具体的实例。

程序总是运行在某个进程的上下文中。（可以理解为进程是程序的载体，进程是一堆地址空间等程序运行的物理条件。）

#### 8.5.1 信号术语：

一个发出而没有被接收的信号叫做**待处理信号(pending signal)**。在任何时刻，一种类型至多只有**一个**待处理信号，其他的会被**丢弃**。一个进程可以选择的阻塞某种信号，然后那种信号只能发送，但产生的待处理信号不会被接收，直到进程取消阻塞它。

一个待处理信号最多只能被接收一次。

#### 8.5.2 发送信号：

进程组ID通常取自作业中父进程中的一个。

#### 8.5.3 接收信号：

进程可以通过使用`signal`函数修改和信号相关联的默认行为，唯一**例外**是`SIGSTOP`和`SIGKILL`。

在某些系统中，被中断的系统调用会立即返回一个错误。

#### 8.5.5 编写信号处理程序：

信号处理是Linux系统编程**最棘手**的问题。

**处理程序的属性：**

1. 与主程序并发运行，共享同样的全局变量，因此可能与主程序和其他处理程序**互相干扰**
2. 如何以及何时接收信号的规则常常有违人的直觉
3. 不同系统有不同的信号处理**语义**

编写处理程序出错时非常难以处理和调试，一定要**防患于未然**。

**编写处理程序的规则：**

1. 处理程序尽可能**简单**
2. 在处理程序中只调用**异步信号安全**的函数。（注：许多常见的函数(printf, sprintf, malloc和exit)都不在此列）
3. 保存和恢复`errno`
4. 阻塞所有信号，保护对共享全局数据结构的访问
5. 用`volatile`声明全局变量（告诉编译器不要缓存这个变量）
6. 用`sig_atomic_t`声明标志（注：这里的原子性只适用于**单个的**读和写，不适用于像`flag++`或`flag = flag + 10`这样的可能需要**多条指令**的更新）

我们的规则是**保守的**，即不总是都要满足，看情况满足即可。但还是建议遵守，毕竟你的判断（断言）很难证明是完全没问题的。

> 不可用信号对其他进程中发生的事件计数，因为只能有一个待处理信号，其他待处理信号都会被丢弃，无法正确保存信息。

**不同系统不同语义：**

1. `signal`函数语义不同：有些老Unix系统上信号k被处理程序捕获之后就把对信号k的反应恢复到默认值。在这些系统上，每次运行之后，处理程序必须调用`signal`函数显式地重新设置它自己
2. 系统调用可被中断：在某些较早版本的Unix中，处理程序捕获到一个信号后时，被中断的慢速系统调用在信号处理程序返回时不再继续，而是立即返回给用户一个错误条件，并将`errno`设置为`EINTR`。在这些系统上，程序员必须**手动重启**被中断的系统调用的代码。（**慢速系统调用：**像`read`, `write`和`accept`这样的系统调用潜在地会阻塞进程一段较长的时间，称为慢速系统调用）

#### 8.5.6 同步流以避免讨厌的并发错误：

**注意：**子进程继承了他们父进程的被阻塞集合，所以我们必须在调用`execve`之前，小心地解除子进程中阻塞的`SIGCHILD`信号。

#### 8.6 非本地跳转(goto)：

C语言提供了一种用户级异常控制流形式，称为非本地跳转(nonlocal jump)，他将控制直接从一个函数转移到另一个当前正在执行的函数。

`setjmp`返回的值不能被赋值给变量，不过它可以安全地用在`switch`或条件语句的测试中。

**重要应用：**

允许从一个深层嵌套的函数调用中立即返回。（错误处理）

**缺陷：**

可能产生内存泄漏，因为跳过了资源释放代码。

**C++和Java中的软件异常：**

C++和Java提供的异常机制是较高层次的，是C语言的`setjmp`和`longjmp`函数的**更加结构化**的版本。你可以把`try`语句中的`catch`子句看作类似于`setjmp`函数，而`throw`语句相当于`longjmp`。

#### 8.7 操作进程的工具：

1. STRACE：打印系统调用的轨迹。用`-static`编译，能得到一个更干净的输出轨迹
2. PS
3. TOP
4. PMAP
5. /proc：如`cat /proc/loadavg`：输出平均负载。

### 第九章、虚拟内存：

